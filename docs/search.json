{
  "articles": [
    {
      "path": "blog.html",
      "title": "Blog listing",
      "description": "This blog contains a mixture of posts on computacional reproducibilty, research integrity, R and academia.\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:24+02:00"
    },
    {
      "path": "code_of_conduct.html",
      "title": "Code of Conduct",
      "author": [],
      "contents": "\r\n\r\nTo ensure a welcoming environment for all, we require everyone participating in the course to conform to the Code of Conduct given below. This code applies to all spaces related to the course including, but not limited to, classroom, ‘aula virtual’, emails, shared documents, and code repositories. We strongly recommend that anyone running workshops or classes of any kind choose and publish a similar code so that everyone will know what is expected of them and what to do when those expectations are not met.\r\n\r\nYou can report Code of Conduct violations in person to Carlos Granell.\r\nWe are dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. However, we recognize that some groups in our community are subject to historical and ongoing discrimination, and may be vulnerable or disadvantaged. Membership in such a specific group can be on the basis of characteristics such as gender, sexual orientation, disability, physical appearance, body size, race, nationality, sex, color, ethnic or social origin, pregnancy, citizenship, familial status, veteran status, genetic information, religion or belief, political or any other opinion, membership of a national minority, property, birth, age, or choice of text editor. We do not tolerate harassment of participants on the basis of these categories, or for any other reason.\r\nHarassment is any form of behavior intended to exclude, intimidate, or cause discomfort. Because we are a diverse community, we may have different ways of communicating and of understanding the intent behind actions. Therefore we have chosen to prohibit certain forms of behavior in our community, regardless of intent.\r\nProhibited harassing behavior includes but is not limited to:\r\nwritten or verbal comments which have the effect of excluding people on the basis of membership of a specific group listed above;\r\ncausing someone to fear for their safety, such as through stalking, following, or intimidation;\r\nthe display of sexual or violent images;\r\nunwelcome sexual attention;\r\nnon-consensual or unwelcome physical contact;\r\nsustained disruption of talks, events or communications;\r\nincitement to violence, suicide, or self-harm;\r\ncontinuing to initiate interaction (including photography or recording) with someone after being asked to stop; and\r\npublication of private communication without consent.\r\nBehavior not explicitly mentioned above may still constitute harassment. The list above should not be taken as exhaustive but rather as a guide to make it easier to enrich all of us and the communities in which we participate. All interactions should be professional regardless of location: harassment is prohibited whether it occurs on or offline, and the same standards apply to both.\r\nEnforcement of the Code of Conduct will be respectful and not include any harassing behaviors.\r\nThank you for helping make this a welcoming, friendly community for all.\r\n[This code of conduct is a simplification of the CoC for Reproducible Research workshos at AGILE, which is based on a CoC for Teaching Tech Together by Greg Wilson, which in turn is based on that used by PyCon, which in turn is forked from a template written by the Ada Initiative and hosted on the Geek Feminism Wiki.]\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:26+02:00"
    },
    {
      "path": "glossary.html",
      "title": "Glossary",
      "author": [],
      "contents": "\r\n\r\nContents\r\nOpen Access\r\nOpen Data\r\nOpen Science\r\nOpen Source\r\nReproducibility\r\nRepricability\r\n\r\nTo clarify the meaning of some key terms and concepts used throughout this course, such as replication, replicability, open science, and open data, we briefly define them below.\r\nOpen Access\r\nOpen access content is accessible to all with limited or no copyright and licensing restrictions: no authentication requirements, no resources under an embargo, no paid access, etc. Content may concern scientific publications, data, code, documentation, and any other research artefact relevant to produce or interpret correctly the results of the research.\r\nOpen Data\r\nOpen data refers to the research data gathered or used during a research project and is made available for access and re-use.\r\nOpen Science\r\nFor (MR et al. 2017), “open science refers to the process of making the content and process of producing evidence and claims transparent and accessible to others.”\r\nOpen Source\r\nSoftware artefact that can be publicly accessed, with a license that allows its use, creation of derivatives and distribution.\r\nReproducibility\r\nThe ability of another researcher or team to obtain the same results using the same methods and data (and most likely using the same or similar computational environment) from the original study.\r\nRepricability\r\nThe ability of another researcher or team to obtain results consistent with the original study using different methods and/or data (and most likely using a similar computational environment).\r\n\r\n\r\n\r\nMR, Munafò, Nosek BA, Bishop DVM, Button KS, Chambers CD, Percie du Sert N, Simonsohn U, Wagenmakers E-J, Ware JJ, and Ioannidis JPA. 2017. “A Quick Guide to Software Licensing for the Scientist-Programmer.” Nature Human Behaviour 1 (0021). https://doi.org/10.1038/s41562-016-0021.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:28+02:00"
    },
    {
      "path": "index.html",
      "title": "What can I do to make my next article (more) reproducible?",
      "description": "[UJI Doctoral School](https://www.uji.es/estudis/centres/escola-doctorat/base/info-general/escola/)'s cross-disciplinary training course on recommendations and best practices about open and reproducible research - [Academic year 2022/2023](https://www.uji.es/estudis/centres/escola-doctorat/base/arxiu/Formacio-transversal/22-23/recerca/reproducible/).\n",
      "author": [
        {
          "name": "Carlos Granell",
          "url": "http://carlosgranell.eu"
        },
        {
          "name": "Sergi Trilles",
          "url": "http://www3.uji.es/~strilles/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nCourse identification\r\nPurpose\r\nLearning outcomes\r\nGetting started\r\nAcknowledgements\r\n\r\n\r\n\r\n\r\nThis introductory course is currently scheduled to be offered in 2 or 3 weeks. While the course is running, some material might not be visible and will be unlocked as the course proceeds. At any other time, this website is continuously online, with small updates happening on an ongoing basis and larger updates every time the course is offered again.\r\nCourse identification\r\nCode/Name: MI007.TMP - Reproducible Research Practices\r\nDuration: 6 hours (up to 20 hours including attendance and self-directed work)\r\nDates: 18 and 25 April, 2 May 2023, from 10 to 12\r\nRoom: TD2203AA\r\nTeaching language: English (Note: in Spanish even years, in English odd years)\r\nTeaching staff:\r\nCarlos Granell  Associate Professor in Computer Science  Office UB1520DD, Espaitec2, 5th floor  Universitat Jaume I, Spain\r\nSergi Trilles  PostDoc - JdC  Office UB-1518DD, Espaitec2, 5th floor  Universitat Jaume I, Spain\r\nDetail course description in Spanish and English\r\nPurpose\r\nThis course emphasises the principles and strategies of open science and reproducible research practices and gives you practice in their application to present scientific and technical material in an informative and clear manner.\r\nWe are not talking about “learning to programme” as a course objective or “knowing how to programme” as a previous requirement. Of course, an open mindset is presupposed so that the course participants can incorporate new practices/recommendations into their research process.\r\nLearning outcomes\r\nBriefly, the course’s learning outcomes are to help you:\r\n[RRP01] Recognise the importance of (computational) reproducible research as a fundamental pillar of open science.\r\n[RRP02] Compare and contrast the RE-* terms (reproduce, replicate, recreate, etc) within the context of each participant’s own discipline.\r\n[RRP03] Describe and distinguish the reproducibility criteria.\r\n[RRP04] Assess participants’ own work according to the reproducibility criteria.\r\n[RRP05] Organise a research project to facilitate reproducibility, openness and reuse.\r\n[RRP06] Contrast the main families of licences for software and data.\r\n[RRP07] Understand the value of combining questions, source code and outcomes.\r\n[RRP08] Apply notebooks to the documentation of computational analyses.\r\n[RRP09] Design and create notebooks for producing academic articles, technical reports or presentations.\r\n[RRP09] Create a Reproduction Plan and reflect on the next steps to achieve it.\r\nGetting started\r\nThis web site is the main theatre entrance to the play of reproducible research practices, and participants, you all, are the main performers! To start, click on casting to get general information about the course, such as the code of conduct, roles in the play (or learning persona) and the acts (or course schedule). Tonight’s play, with acts and scenes, is ready to be performed on the stage. If you like it, feel free to go backstage to inspect additional documents and materials to go deeper into this topic. If you really, really love the topic (and read Spanish), meet the crew behind the curtain.\r\nAcknowledgements\r\nThis course was developed and is maintained by Carlos Granell. Nevertheless, the following individuals have contributed to improving the course: Daniel Nüst, Frank Ostermann, Markus Konkol.\r\nThe course materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Linked materials are governed by their own licenses. I assume that all external materials used here are covered under the educational fair use policy. If this is not the case and any material displayed here violates copyright, please let me know and I will remove it.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:30+02:00"
    },
    {
      "path": "personas.html",
      "title": "Learner Personas",
      "author": [],
      "contents": "\r\n\r\nContents\r\nCeline\r\nVíctor\r\nJuan\r\nAna\r\n\r\nLike you, a Learner Persona (Wilson 2019)) consists of:\r\na general background,\r\nwhat you already know,\r\nwhat you want to know, and\r\nother special needs you may have.\r\nIf you are working on your doctoral thesis, do you identify better with Celine or with Víctor? If you are part of the teaching staff, do your learning needs fit better with those of Juan or with those of Ana?\r\nCeline\r\nCeline has a degree in psychology from England and has just enrolled in the UJI doctoral school. Her doctoral thesis deals with the application of new technologies to improve behavioral therapies for patients diagnosed with gambling addiction.\r\nCeline plans to carry out several experiments with patients during her doctoral period. She knows some tools for data analysis (such as SPSS) from her bachelor’s degree, but she has never taken a formal programming course, although she has thought about it often. She sometimes thinks that she suffers from the impostor syndrome as soon as she faces with programming languages or advanced data analytical tools.\r\nCeline would like to systematize the data analysis of the experiments that she will be conducting in her doctoral project. Yet, above all, she wants to prove to herself that she can learn computational competences. The terms reproducibility and replicability sound familiar to her and she thinks that they can be useful to speed up the tedious work of her experiments, but she does not know where to start.\r\nVíctor\r\nVíctor studied a chemistry degree at UJI and is in the final phase of his PhD thesis on computational chemistry, which he hopes to defend once he completes a planned research stay in France.\r\nVíctor learned R early in his thesis period and it is still the programming language in his research. Like in many other tools, he was self-taught in the use of Github and uses it to version his own software and to collaborate with other colleagues. He has published some relevant articles in which the developed software has been a main contribution.\r\nVíctor wants to improve his skills and expand his knowledge about reproducibible workflows. The best academic journals in his field now require that every submission come with code and data, and he knows that an article published in those high-profile journals can open the door to a postdoc.\r\nJuan\r\nJuan is a professor of Economics at the UJI. He has four six-year research periods and a good record of scientific publications. He is responsible for a quantitative economics course which in turn is the focus of his research.\r\nJuan is surprised by the current hype about the reproducibility crisis that he reads about in Science and Nature editorials. He considers that crisis an exaggeration, like so many other buzzwords that he has witnessed in his long academic career. He has never needed reproducibility to have a successful academic career.\r\nDespite this, Juan wants to make sure that his beliefs about reproducibility and reproducible practices are well founded.\r\nAna\r\nAna is a professor of Computer Science at the UJI. She hardly never investigates, but she is very active and is concerned with improving her teaching practices. She is responsible for an introductory programming course for large groups of freshmen.\r\nAna is up to date with teaching innovations and everything related to educational technology. For a decade, she has been applying the most recent learning methodologies and innovative techniques in her classes with considerable success, according to what her students say in surveys.\r\nAna wants to know if reproducibility and teaching combine in some way, since reproducibility and research always go hand in hand in everything she has read. She is wodering how to bring reproduciblity aspects into her practical sessions, such as in peer asessment and peer instructions, and even for the creation of teaching materials. She is interested in guides and practical examples to get inspired to improving her teaching materials and practical classes.\r\n\r\n\r\n\r\nWilson, Greg. 2019. Teaching Tech Together: How to Make Lessons That Work and Build a Teaching Community Around It. Taylor & Francis. https://teachtogether.tech/.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:32+02:00"
    },
    {
      "path": "references.html",
      "title": "References",
      "description": "This page lists resources that this course draws on frequently or at least occasionally.\n",
      "author": [],
      "contents": "\r\nAll materials described below are (should be) freely available online. If you cannot get to them, let me know. Note that a lot of the listed resources are dynamic and ever changing. That means occasionally links might not work, sites go down. If you notice anything that’s not quite right, please let me know.\r\n\r\n\r\n\r\nAden-Buie, Garrick, Barret Schloerke, JJ Allaire, and Alexander Rossell Hayes. 2023. Learnr: Interactive Tutorials for r. https://rstudio.github.io/learnr/.\r\n\r\n\r\nAlsheikh-Ali, Alawi A., Waqas Qureshi, Mouaz H. Al-Mallah, and John P. A. Ioannidis. 2011. “Public Availability of Published Research Data in High-Impact Journals.” PLOS ONE 6 (9): 1–4. https://doi.org/10.1371/journal.pone.0024357.\r\n\r\n\r\nAlston, Jesse M., and Jessica A. Rick. 2021. “A Beginner’s Guide to Conducting Reproducible Research.” The Bulletin of the Ecological Society of America 102 (2): e01801. https://doi.org/https://doi.org/10.1002/bes2.1801.\r\n\r\n\r\nBaker, M. 2015. “First Results from Psychology’s Largest Reproducibility Test.” Nature News. https://doi.org/10.1038/nature.2015.17433.\r\n\r\n\r\n———. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\r\n\r\n\r\n———. 2017. “Check Your Chemistry.” Nature 548 (7668): 485–88. https://doi.org/10.1038/548485a.\r\n\r\n\r\nBarba, L. 2018. “Terminologies for Reproducible Research.” arXiv Preprint arXiv:1802.03311. https://arxiv.org/abs/1802.03311.\r\n\r\n\r\nBarba, Lorena A. 2021. “Trustworthy Computational Evidence Through Transparency and Reproducibility.” Computing in Science & Engineering 23 (1): 58–64. https://doi.org/10.1109/MCSE.2020.3048406.\r\n\r\n\r\nBarker, Michelle, Neil P. Chue Hong, Daniel S. Katz, Anna-Lena Lamprecht, Carlos Martinez-Ortiz, Fotis Psomopoulos, Jennifer Harrow, et al. 2022. “Introducing the FAIR Principles for Research Software.” Scientific Data 9 (1). https://doi.org/10.1038/s41597-022-01710-x.\r\n\r\n\r\nBerti, Johann, Marin Dacos, Gabriel Gallezot, Madeleine Géroudet, Sabrina Granger, Joanna Janik, Claire Josserand, et al. 2022. “Passport for Open Science - a Practical Guide Ofr PhD Students.” University of Lille. https://www.ouvrirlascience.fr/passport-for-open-science-a-practical-guide-for-phd-students/.\r\n\r\n\r\nBiggs, John, and Catherine Tang. 2011. Teaching for Quality Learning at University, 4th Edition. Open University Press.\r\n\r\n\r\nBion, R, R Chang, and J Goodman. 2018. “How r Helps Airbnb Make the Most of Its Data.” The American Statistician 72 (1): 46–52. https://doi.org/10.1080/00031305.2017.1392362.\r\n\r\n\r\nBryan, Jennifer. 2018. “Excuse Me, Do You Have a Moment to Talk about Version Control?” The American Statistician 72 (1): 20–27. https://doi.org/10.1080/00031305.2017.1399928.\r\n\r\n\r\nBryan, Jenny, and Jim Hester. 2020. Happy Git and GitHub for the useR. https://happygitwithr.com/.\r\n\r\n\r\nButton, KS, JPA Ioannidis, C Mokrysz, BA Nosek, J Flint, ESJ Robinson, and MR Munafò. 2013. “Power Failure: Why Small Sample Size Undermines the Reliability of Neuroscience.” Nature Reviews Neuroscience 14 (5): 365–76. https://doi.org/10.1038/nrn3475.\r\n\r\n\r\nCallaghan, S. 2014. “Joint Declaration of Data Citation Principles.” https://www.force11.org/datacitationprinciples.\r\n\r\n\r\nChiarelli, Andrea, Lucia Loffreda, and Rob Johnson. 2021. “The Art of Publishing Reproducible Research Outputs: Supporting emerging practices through cultural and technological innovation.” Zenodo. https://doi.org/10.5281/zenodo.5521077.\r\n\r\n\r\nClaerbout, JF, and M Karrenbach. 1992. “Electronic Documents Give Reproducible Research a New Meaning.” In SEG Technical Program Expanded Abstracts 1992, 601–4. Society of Exploration Geophysicists. https://doi.org/10.1190/1.1822162.\r\n\r\n\r\nCooper, Natalie, and Pen-Yuah Hsing. 2019. “Reproducible Code.” British Ecological Society. https://www.britishecologicalsociety.org/publications/guides-to/.\r\n\r\n\r\nDelgado-López-Cózar, E, I Ràfols, and E Abadal. 2021. “Letter: A Call for a Radical Change in Research Evaluation in Spain.” Profesional de La Información 30 (3): e300309. https://doi.org/10.3145/epi.2021.may.09.\r\n\r\n\r\nDhar, Payal. 2023. “Octopus and ResearchEquals Aim to Break the Publishing Mould.” Nature. Springer Science; Business Media LLC. https://doi.org/10.1038/d41586-023-00861-0.\r\n\r\n\r\nDonoho, DL, A Maleki, IU Rahman, M Shahram, and V Stodden. 2009. “Reproducible Research in Computational Harmonic Analysis.” Computing in Science & Engineering 11 (1): 8–18. https://doi.org/10.1109/MCSE.2009.15.\r\n\r\n\r\nEditorial. 2021. “Good Research Begins Long Before Papers Get Written.” Nature 593 (7857): 8–8. https://doi.org/10.1038/d41586-021-01167-9.\r\n\r\n\r\nFanelli, D. 2018. “Opinion: Is Science Really Facing a Reproducibility Crisis, and Do We Need It To?” Proceedings of the National Academy of Sciences 115 (11): 2628–31. https://doi.org/10.1073/pnas.1708272114.\r\n\r\n\r\nGranell, C. 2019. “Directrices Para Articulos Reproducibles.” https://doi.org/10.17605/OSF.IO/MF9BE.\r\n\r\n\r\nGranell, C, B Hofer, Daniel Nüst, FO Ostermann, and R Sileryte. 2020. “Reproducibilidad En AGILE: Experiencias, Logros y Recomendaciones.” Revista Cartográfica, no. 100: 155–72. https://doi.org/10.35424/rcarto.i100.668.\r\n\r\n\r\nGranell, C, Daniel Nüst, FO Ostermann, and R Sileryte. 2018. “Reproducible Research Is Like Riding a Bike.” PeerJ Preprints 6: e27216v1. https://doi.org/10.7287/peerj.preprints.27216v1.\r\n\r\n\r\nHarrison, Kate. 2018. “Data Management.” British Ecological Society. https://www.britishecologicalsociety.org/publications/guides-to/.\r\n\r\n\r\nHasselbring, Wilhelm, Leslie Carr, Simon Hettrick, Heather Packer, and Thanassis Tiropanis. 2020. “Open Source Research Software.” Computer 53 (8): 84–88. https://doi.org/10.1109/MC.2020.2998235.\r\n\r\n\r\nHong, NPC, T Crick, IP Gent, L Kotthoff, and K Takeda. 2015. “Top Tips to Make Your Research Irreproducible.” arXiv Preprint arXiv:1504.00062. https://arxiv.org/abs/1504.00062.\r\n\r\n\r\nIoannidis, JP. 2005. “Why Most Published Research Findings Are False.” PLOS Medicine 2 (8): e124. https://doi.org/10.1371/journal.pmed.0020124.\r\n\r\n\r\nIoannidis, JP, TD Stanley, and H Doucouliagos. 2017. “The Power of Bias in Economics Research.” The Economic Journal 127 (605): F236–65. https://doi.org/10.1111/ecoj.12461.\r\n\r\n\r\nJolly, M, AC Fletcher AC, and PE Bourne. 2012. “Ten Simple Rules to Protect Your Intellectual Property.” PLoS Computacional Biology 8: e1002766. https://doi.org/10.1371/journal.pcbi.1002766.\r\n\r\n\r\nKeshav, S. 2007. “How to Read a Paper.” ACM SIGCOMM Computer Communication Review 37 (3): 83–84. https://doi.org/10.1145/1273445.1273458.\r\n\r\n\r\nKnuth, DE. 1984. “Literate Programming.” The Computer Journal 11 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\r\n\r\n\r\nLeek, JT, and LR Jager. 2017. “Is Most Published Research Really False?” Annual Review of Statistics and Its Application 4: 109–22. https://doi.org/10.1146/annurev-statistics-060116-054104.\r\n\r\n\r\nLeipzig, Jeremy, Daniel Nüst, Charles Tapley Hoyt, Karthik Ram, and Jane Greenberg. 2021. “The Role of Metadata in Reproducible Computational Research.” Patterns 2 (9): 100322. https://doi.org/https://doi.org/10.1016/j.patter.2021.100322.\r\n\r\n\r\nMacleod, Malcolm, Andrew M. Collings, Chris Graf, Veronique Kiermer, David Mellor, Sowmya Swaminathan, Deborah Sweet, and Valda Vinson. 2021. “The MDAR (Materials Design Analysis Reporting) Framework for Transparent Reporting in the Life Sciences.” Proceedings of the National Academy of Sciences 118 (17): e2103238118. https://doi.org/10.1073/pnas.2103238118.\r\n\r\n\r\nMarkowetz, F. 2015. “Five Selfish Reasons to Work Reproducibly.” Genome Biology 16: 274. https://doi.org/10.1186/s13059-015-0850-7.\r\n\r\n\r\nMesnard, Olivier, and Lorena A. Barba. 2017. “Reproducible and Replicable Computational Fluid Dynamics: It’s Harder Than You Think.” Computing in Science Engineering 19 (4): 44–55. https://doi.org/10.1109/MCSE.2017.3151254.\r\n\r\n\r\nMiralles, Ignacio, Carlos Granell, Laura Díaz-Sanahuja, William Van Woensel, Juana Bretón-López, Adriana Mira, Diana Castilla, and Sven Casteleyn. 2020. “Smartphone Apps for the Treatment of Mental Disorders: Systematic Review.” JMIR Mhealth Uhealth 8 (4): e14897. https://doi.org/10.2196/14897.\r\n\r\n\r\nMorin, A, J Urban, and P Sliz. 2012. “A Quick Guide to Software Licensing for the Scientist-Programmer.” PLoS Computacional Biology 8 (7): e1002598. https://doi.org/10.1371/journal.pcbi.1002598.\r\n\r\n\r\nMR, Munafò, Nosek BA, Bishop DVM, Button KS, Chambers CD, Percie du Sert N, Simonsohn U, Wagenmakers E-J, Ware JJ, and Ioannidis JPA. 2017. “A Quick Guide to Software Licensing for the Scientist-Programmer.” Nature Human Behaviour 1 (0021). https://doi.org/10.1038/s41562-016-0021.\r\n\r\n\r\nNational Academies of Sciences, Engineering, and Medicine. 2019. Reproducibility and Replicability in Science. The National Academies Press. https://doi.org/10.17226/25303.\r\n\r\n\r\nNosek, Brian A., and Timothy M. Errington. 2020. “What is replication?” PLOS Biology 18 (3): e3000691. https://doi.org/10.1371/journal.pbio.3000691.\r\n\r\n\r\nNoy, Natasha, and Carole Goble. 2023. “Are We Cobblers without Shoes?” Communications of the ACM 66 (1): 36–38. https://doi.org/10.1145/3528574.\r\n\r\n\r\nNoy, Natasha, and Aleksandr Noy. 2019. “Let Go of Your Data.” Nature Materials 19 (1): 128–28. https://doi.org/10.1038/s41563-019-0539-5.\r\n\r\n\r\nNust, Daniel, Carl Boettiger, and Ben Marwick. 2018. “How to Read a Research Compendium.” arXiv. https://doi.org/10.48550/ARXIV.1806.09525.\r\n\r\n\r\nNust, Daniel, C Granell, B Hofer, M Konkol, FO Ostermann, R Sileryte, and V Cerutti. 2018. “Reproducible Research and GIScience: An Evaluation Using AGILE Conference Papers.” PeerJ 6: e5072. https://doi.org/10.7717/peerj.5072.\r\n\r\n\r\nNust, Daniel, FO Ostermann, R Sileryte, B Hofer, C Granell, M Teperek, A Graser, K Broman, and K Hettne. 2018. “AGILE Reproducible Paper Guidelines.” https://doi.org/10.17605/OSF.IO/CB7Z8.\r\n\r\n\r\nNust, Daniel, Frank Ostermann, Rusne Sileryte, Barbara Hofer, Carlos Granell, Marta Teperek, Anita Graser, et al. 2020. “Reproducible Publications at AGILE Conferences: Guidelines for Authors, Scientific Reviewers, and Reproducibility Reviewers.” https://doi.org/10.17605/OSF.IO/CB7Z8.\r\n\r\n\r\nNust, Daniel, Vanessa Sochat, Ben Marwick, Stephen J. Eglen, Tim Head, Tony Hirst, and Benjamin D. Evans. 2020. “Ten Simple Rules for Writing Dockerfiles for Reproducible Data Science.” PLOS Computational Biology 16 (11): 1–24. https://doi.org/10.1371/journal.pcbi.1008316.\r\n\r\n\r\nNüst, Daniel, and Stephen J Eglen. 2021. “CODECHECK: an Open Science initiative for the independent execution of computations underlying research articles during peer review to improve reproducibility.” F1000Research 10 (March): 253. https://doi.org/10.12688/f1000research.51738.1.\r\n\r\n\r\nOstermann, FO, and C Granell. 2017. “Advancing Science with VGI: Reproducibility and Replicability of Recent Studies Using VGI.” Transactions in GIS 21 (2): 224–37. https://doi.org/10.1111/tgis.12195.\r\n\r\n\r\nOstermann, Frank O., Daniel Nüst, Carlos Granell, Barbara Hofer, and Markus Konkol. 2021. “Reproducible Research and GIScience: An Evaluation Using GIScience Conference Papers.” In 11th International Conference on Geographic Information Science (GIScience 2021) - Part II, edited by Krzysztof Janowicz and Judith A. Verstegen, 208:2:1–16. Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl – Leibniz-Zentrum für Informatik. https://doi.org/10.4230/LIPIcs.GIScience.2021.II.2.\r\n\r\n\r\nParsons, MA, RE Duerr, and MB Jones. 2019. “The History and Future of Data Citation in Practice.” Data Science Journal 18 (1). https://doi.org/10.5334/dsj-2019-052.\r\n\r\n\r\nPeng, RD. 2011. “Reproducible Research in Computational Science.” Science 334 (6060): 1226–27. https://doi.org/10.1126/science.1213847.\r\n\r\n\r\nPerez-Riverol, Y, L Gatto, R Wang, T Sachsenberg, J Uszkoreit, F da Veiga Leprevost, C Fufezan, et al. 2016. “Ten Simple Rules for Taking Advantage of Git and GitHub.” PLoS Computational Biology 12 (7). https://doi.org/10.1371/journal.pcbi.1004947.\r\n\r\n\r\nPimentel, João Felipe, Leonardo Murta, Vanessa Braganholo, and Juliana Freire. 2019. “A Large-Scale Study about Quality and Reproducibility of Jupyter Notebooks.” In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), 507–17. https://doi.org/10.1109/MSR.2019.00077.\r\n\r\n\r\nRule, A, A Birmingham, C Zuniga, I Altintas, SC Huang, R Knight, N Moshiri, et al. 2019. “Ten Simple Rules for Reproducible Research in Jupyter Notebooks.” PLoS Computational Biology 15 (7): e1007007. https://doi.org/10.1371/journal.pcbi.1004947.\r\n\r\n\r\nSandve, GK, A Nekrutenko, J Taylor, and E Hovig. 2017. “Ten Simple Rules for Reproducible Computational Research.” PLoS Computacional Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\r\n\r\n\r\nSmith, AM, DS Katz, and KE Niemeyer. 2016. “Software Citation Principles.” PeerJ Computer Science 2: e86. https://doi.org/10.7717/peerj-cs.86.\r\n\r\n\r\nStark, PB. 2018. “Before Reproducibility Must Come Preproducibility.” Nature 557 (7706): 613–14. https://doi.org/10.1038/d41586-018-05256-0.\r\n\r\n\r\nStodden, Victoria, Jennifer Seiler, and Zhaokun Ma. 2018. “An Empirical Analysis of Journal Policy Effectiveness for Computational Reproducibility.” Proceedings of the National Academy of Sciences 115 (11): 2584–89. https://doi.org/10.1073/pnas.1708290115.\r\n\r\n\r\nStodden, V, and SB Miguez. 2014. “Best Practices for Computational Science: Software Infrastructure and Environments for Reproducible and Extensible Research.” Journal of Open Research Software 2 (1): e21. https://doi.org/10.5334/jors.ay.\r\n\r\n\r\nTenopir, C, S Allard, K Douglass, AU Aydinoglu, L Wu, E Read, M Manoff, and M Frame. 2011. “Data Sharing by Scientists: Practices and Perceptions.” PLoS ONE 6 (6): e21101. https://doi.org/10.1371/journal.pone.0021101.\r\n\r\n\r\nTenopir, C, ED Dalton, S Allard, M Frame, I Pjesivac, B Birch, D Pollock, and K Dorsett. 2015. “Changes in Data Sharing and Data Reuse Practices and Perceptions Among Scientists Worldwide.” PLoS ONE 10 (8): e0134826. https://doi.org/10.1371/journal.pone.0134826.\r\n\r\n\r\nTenopir, C, NM Rice, S Allard, L Baird, J Borycz, L Christian, B Grant, R Olendorf, and RJ Sandusky. 2020. “Data Sharing, Management, Use, and Reuse: Practices and Perceptions of Scientists Worldwide.” PLoS ONE 15 (3): e0229003. https://doi.org/10.1371/journal.pone.0229003.\r\n\r\n\r\nThe Turing Way Community. 2019. “The Turing Way: A Handbook for Reproducible Data Science.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\r\n\r\n\r\nTso, Chak Hau Michael, Michael Hollaway, Rebecca Killick, Peter Henrys, Don Monteith, John Watkins, and Gordon Blair. 2022. “The r Journal: Advancing Reproducible Research by Publishing r Markdown Notebooks as Interactive Sandboxes Using the Learnr Package.” The R Journal 14: 255–63. https://doi.org/10.32614/RJ-2022-021.\r\n\r\n\r\nVasilevsky, NA, J Minnier, MA Haendel, and RE Champieux. 2017. “Reproducible and Reusable Research: Are Journal Data Sharing Policies Meeting the Mark?” PeerJ 5: e3208. https://doi.org/10.7717/peerj.3208.\r\n\r\n\r\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3 (1). https://doi.org/10.1038/sdata.2016.18.\r\n\r\n\r\nWilson, C. 2021. “Impact Factor Abandoned by Dutch University in Hiring and Promotion Decisions.” Nature 595 (465). https://doi.org/10.1038/d41586-021-01759-5.\r\n\r\n\r\nWilson, G, J Bryan, K Cranston, J Kitzes, L Nederbragt, and TK Teal. 2017. “Good Enough Practices in Scientific Computing.” PLoS Computacional Biology 13 (6): e1005510. https://doi.org/10.1371/journal.pcbi.1005510.\r\n\r\n\r\nWilson, Greg. 2019. Teaching Tech Together: How to Make Lessons That Work and Build a Teaching Community Around It. Taylor & Francis. https://teachtogether.tech/.\r\n\r\n\r\nWood-Charlson, Elisha M., Zachary Crockett, Chris Erdmann, Adam P. Arkin, and Carly B. Robinson. 2022. “Ten Simple Rules for Getting and Giving Credit for Data.” PLOS Computational Biology 18 (9): 1–11. https://doi.org/10.1371/journal.pcbi.1010476.\r\n\r\n\r\nXie, Y. 2019. Bookdown: Authoring Books and Technical Documents with r Markdown. CRC Press. https://bookdown.org/yihui/bookdown/.\r\n\r\n\r\nXie, Y, JJ Allaire, and G Grolemund. 2018. R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:34+02:00"
    },
    {
      "path": "scene11.html",
      "title": "Act I &#183; Setting the stage",
      "description": "Scene 1 &#183; Reproducibility and replicability\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP01] Recognise the importance of (computational) reproducible research as a fundamental pillar of open science.\r\n[RRP02] Compare and contrast the {Re}* terms (reproduce, replicate, recreate, etc) within the context of each participant’s own discipline.\r\nContent…\r\nWe recognize the importance of reproduction and replication as part of the scientific method and open science.\r\nWe introduce the concepts of reproducibility and replicability.\r\nWe compare reproduction practices and standards required/perceived in different disciplines or areas of knowledge.\r\nOrganisation & materials\r\n[Estimated time: 2 hours]\r\nOf the examples of Learner Personas, with which one do you identify the most, even if it doesn’t quite fit your profile?\r\nReview the concepts of reproducibility, replication, and computational reproducibility in Reproducibility: historical notes & concept (slides) .\r\n\r\n\r\n\r\n\r\n\r\nReflect on the extent to which these terms (reproduction, replication, robustness, generalisation) are widespread in your own discipline or area of research. Which is more predominant in your discipline? And in your research? Of the journals you publish or flag-ship journals in your discipline, do they request articles that support computational reproducibility, empirical reproducibility, or statistical reproducibility? (hint: check The Turing Way’s definitions page (The Turing Way Community 2019)).\r\n(Optional) If you’re still hesitant to embrace reproducibility, Five Selfish Reasons to Work Reproducibly by Dr. Florian Markowetz], based on his paper (Markowetz 2015), will convince you!\r\nAssignments\r\nIndicate the Learner Persona with whom you best identify (activity 1) in the Learner Persona Survey in AV.\r\nWrite a message (min 150 words) to answer the questions posed in Activity 3 above to the forum Reflection on reproducibility/replicability in your discipline and in your own research in AV. Please, indicate in the message your discipline or area of knowledge.\r\n\r\n\r\n\r\nMarkowetz, F. 2015. “Five Selfish Reasons to Work Reproducibly.” Genome Biology 16: 274. https://doi.org/10.1186/s13059-015-0850-7.\r\n\r\n\r\nThe Turing Way Community. 2019. “The Turing Way: A Handbook for Reproducible Data Science.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:37+02:00"
    },
    {
      "path": "scene12.html",
      "title": "Act I &#183; Setting the stage",
      "description": "Scene 2 &#183; PhD meets open science\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP01] Recognise the importance of (computational) reproducible research as a fundamental pillar of open science.\r\nContent…\r\nWe identify resources that are part of the scientific process, beyond the published scientific article.\r\nWe discuss the role of Open Science and reproduction in a PhD project.\r\nOrganisation & materials\r\n[Estimated time: 2 hours]\r\nTo get some context on how reproducibility and Open Science fit into your research process and practices: “Open, reproducible, and replicable (PhD) research” (slides).\r\nReflect on your research process and practices in general (do not focus on a specific project or article) and answer the following questions.\r\nIndicates department and/or research group.\r\nDo you carry out theoretical-conceptual, practical-experimental research, or a combination of them?\r\nDoes input data play an important role in your research? Do you use existing data sources? Or do you generate the data expressly for your research (eg questionnaires)?\r\nDo you need to adjust, fix, clean, aggregate, that is, pre-process input data for your research?\r\nDo you carry out any analysis or apply any model on the data? Do you use any existing technology tools for analysis, or do you write your own code to analyse the data? Or both?\r\nAre the tables, figures, graphs, maps or diagrams common results in your research, that is, do they frequently appear in your final reports or articles?\r\nAssignments\r\nAnswer the questions posed in Activity 2 above to the corresponding activity in AV.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:39+02:00"
    },
    {
      "path": "scene13.html",
      "title": "Act I &#183; Setting the stage",
      "description": "Scene 2 &#183; Pre-reproducibility assessment\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP03] Describe and distinguish the reproducibility criteria.\r\n[RRP04] Assess participants’ own own research papers or scientific writings according to the reproducibility criteria.\r\nContent…\r\nWe identify resources that are part of the scientific process, beyond the published scientific article.\r\nWe characterise these resources according to reproducibility criteria.\r\nWe use and interpret correctly the levels associated with each criterion.\r\nOrganisation & materials\r\n[Estimated time: 2 hours]\r\nIf you are very interested in a paper, you want to understand the inner aspects pretty well. So, you give reproducibility a try. It is then advisable to assess first the level of pre-reproducibility of a paper before attempting a real reproduction.\r\nRead the first three sections (Introduction, Related Work, Materials & Methods) of the following paper (Nust et al. 2018), where a set of criteria are proposed to evaluate the degree of reproducibility of an article. (If motivated, you can also read the section 3.1 of the paper (Ostermann et al. 2021).) Pay attention to figure 2, which outlines the levels for each of the reproducibility criteria. You should familiarise yourself with these criteria and their levels to carry out the first activity of the Reproduction Plan.\r\nAssignments\r\nTo begin with the Reproduction Plan, choose one of your recent published paper or a current draft, and carry out a self-assessment exercise in which you must assign a level (NA Not Applicable, 0 Unavailable, 1 Documented, 2 Available, 3 Available and Open) for each of the reproducibility criteria: Input Data; Preprocessing; Methods, Analysis, Processing; Computational Environment; Results.\r\n\r\n\r\n\r\nNust, Daniel, C Granell, B Hofer, M Konkol, FO Ostermann, R Sileryte, and V Cerutti. 2018. “Reproducible Research and GIScience: An Evaluation Using AGILE Conference Papers.” PeerJ 6: e5072. https://doi.org/10.7717/peerj.5072.\r\n\r\n\r\nOstermann, Frank O., Daniel Nüst, Carlos Granell, Barbara Hofer, and Markus Konkol. 2021. “Reproducible Research and GIScience: An Evaluation Using GIScience Conference Papers.” In 11th International Conference on Geographic Information Science (GIScience 2021) - Part II, edited by Krzysztof Janowicz and Judith A. Verstegen, 208:2:1–16. Leibniz International Proceedings in Informatics (LIPIcs). Dagstuhl, Germany: Schloss Dagstuhl – Leibniz-Zentrum für Informatik. https://doi.org/10.4230/LIPIcs.GIScience.2021.II.2.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:41+02:00"
    },
    {
      "path": "scene21.html",
      "title": "Act II &#183; Recommendations and practices for open and reproducbile research",
      "description": "Scene 1 &#183; Basics to get started\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP05] Organise a research project to facilitate reproducibility, openness and reuse.\r\n[RRP06] Contrast the main families of licences for software and data.\r\nContent…\r\nWe discuss practices and recommendations to get started with reproducibility\r\nWe introduce and compare types of licences\r\nOrganisation & materials\r\n[Estimated time: 4 hours]\r\nThere are excellent practical guides with general recommendations for promoting reproducibility, research data management and open science. This week we’ll take a look at three guides for open science and reproducible research.\r\nThe British Ecological Society publishes brief guidelines for conducting open science on ecology but applicable to any discipline. Among them, the guide Reproducible code (Cooper and Hsing 2019) explains organizational and managerial aspects for making software code more reproducible.\r\nPassport for Open Science: A Practical Guide for PhD Students (Berti et al. 2022) explains how the principles of open science can be applied to doctoral research. The proposed practices are applicable to any discipline and, although focused on doctoral students, they are aimed at any researcher regardless of their previous experience.\r\nA Beginner’s Guide to Conducting Reproducible Research (Alston and Rick 2021) is a very concise, practical guide to apply reproducible practices to a research project.\r\nThe Turing Way is indeed a compendium of guides on open science, reproducibility, and research ethics, among other interesting topics. Have a look at the Guide for Reproducible Research (The Turing Way Community 2019).\r\nAs part of the Open Knowledge Portal, the UJI library includes guides for researchers abpout the open access dissemination of the results of the investigation, copyright and licenses, and the October 2020 institutional statement to promote open access Declaración institucional a favor de la promoción del acceso abierto en la Universitat Jaume I.\r\n\r\n“Before: Basics to get started” (slides)  summarises some of the organizational aspects and reproducible practices for the preparation and first steps of a project.\r\n\r\n\r\n\r\n\r\n\r\nAssignments\r\nTo continue with the Reproduction Plan, identify per each assessment criteria which practices and recommendations you can adopt (or have already adopted) to increase the level of reproducibility of your next paper.\r\n\r\n\r\n\r\nAlston, Jesse M., and Jessica A. Rick. 2021. “A Beginner’s Guide to Conducting Reproducible Research.” The Bulletin of the Ecological Society of America 102 (2): e01801. https://doi.org/https://doi.org/10.1002/bes2.1801.\r\n\r\n\r\nBerti, Johann, Marin Dacos, Gabriel Gallezot, Madeleine Géroudet, Sabrina Granger, Joanna Janik, Claire Josserand, et al. 2022. “Passport for Open Science - a Practical Guide Ofr PhD Students.” University of Lille. https://www.ouvrirlascience.fr/passport-for-open-science-a-practical-guide-for-phd-students/.\r\n\r\n\r\nCooper, Natalie, and Pen-Yuah Hsing. 2019. “Reproducible Code.” British Ecological Society. https://www.britishecologicalsociety.org/publications/guides-to/.\r\n\r\n\r\nThe Turing Way Community. 2019. “The Turing Way: A Handbook for Reproducible Data Science.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:43+02:00"
    },
    {
      "path": "scene22.html",
      "title": "Act II &#183; Recommendations and practices for open and reproducbile research",
      "description": "Scene 2 &#183; Data/coding practices and tools\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP05] Organise a research project to facilitate reproducibility, openness and reuse.\r\n[RRP06] Contrast the main families of licences for software and data.\r\nContent…\r\nWe discuss practices and recommendations to get started with reproducibility\r\nWe introduce and compare types of licences\r\nOrganisation & materials\r\n[Estimated time: 4 hours]\r\nThere are excellent practical guides with general recommendations for promoting reproducibility, research data management and open science. This week we’ll take a look at three guides for open science and reproducible research.\r\nThe British Ecological Society publishes brief guidelines for conducting open science. Read the guide Reproducible code (Cooper and Hsing 2019), which explains organizational aspects focused on ecology but applicable to any discipline.\r\nRead Passport for Open Science: A Practical Guide for PhD Students (Berti et al. 2022), it explains how to develop doctoral research in line with the principles of open science. The proposed practices are applicable to any discipline and, although focused on doctoral students, they are aimed at any researcher regardless of their previous experience.\r\nThe Turing Way is the third resource or guide which indeed is a compendium of guides on open science, reproducibility, and research ethics. The Guide for Reproducible Research (The Turing Way Community 2019) is relevant, particularly the Licensing section.\r\nAs part of the Open Knowledge Portal, the UJI library includes guides for researchers abpout the open access dissemination of the results of the investigation, copyright and licenses, and the October 2020 institutional statement to promote open access Declaración institucional a favor de la promoción del acceso abierto en la Universitat Jaume I.\r\n\r\n“During: Data/coding practices and tools” (slides)  summarises some of the organizational aspects and reproducible practices for the preparation and first steps of a project.\r\n\r\n\r\n\r\n\r\n\r\nAssignments\r\nTo continue with the Reproduction Plan, identify per each assessment criteria which practices and recommendations you can adopt (or have already adopted) to increase the level of reproducibility of your next paper.\r\n\r\n\r\n\r\nBerti, Johann, Marin Dacos, Gabriel Gallezot, Madeleine Géroudet, Sabrina Granger, Joanna Janik, Claire Josserand, et al. 2022. “Passport for Open Science - a Practical Guide Ofr PhD Students.” University of Lille. https://www.ouvrirlascience.fr/passport-for-open-science-a-practical-guide-for-phd-students/.\r\n\r\n\r\nCooper, Natalie, and Pen-Yuah Hsing. 2019. “Reproducible Code.” British Ecological Society. https://www.britishecologicalsociety.org/publications/guides-to/.\r\n\r\n\r\nThe Turing Way Community. 2019. “The Turing Way: A Handbook for Reproducible Data Science.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:46+02:00"
    },
    {
      "path": "scene23.html",
      "title": "Act II &#183; Recommendations and practices for open and reproducible research",
      "description": "Scene 3 &#183; After: writing and sharing reproducible resources\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP05] Organise a research project to facilitate reproducibility, openness and reuse.\r\n[RRP06] Contrast the main families of licences for software and data.\r\nContent…\r\nWe discuss practices and recommendations to get started with reproducibility\r\nWe introduce and compare types of licences\r\nOrganisation & materials\r\n[Estimated time: 4 hours]\r\n“After: writing and sharing reproducible resources” (slides) summarises some of the organizational aspects and reproducible practices for the preparation and first steps of a project.\r\n\r\n\r\n\r\n\r\n\r\nAssignments\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:48+02:00"
    },
    {
      "path": "scene31.html",
      "title": "Act III &#183; Recommendations and practices: GIScience",
      "description": "Scene 1 &#183; AGILE Guidelines\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\n\r\nLearning outcomes…\r\n[RRP05] Organise a research project to facilitate reproducibility, openness and reuse.\r\n[RRP06] Contrast the main families of licences for software and data.\r\nContent…\r\nWe discuss practices and recommendations to get started with reproducibility\r\nOrganisation & materials\r\n[Estimated time: 4 hours]\r\nWho are we? A brief historical account of reproducibility in the AGILE conference series. Check out Reproducible Research @ AGILE\r\nReproducible Publications at AGILE Conferences – Guidelines for Authors, Scientific Reviewers, and Reproducibility Reviewers (December 2020)\r\nReproducible Publications at AGILE Conferences – Spanish translation (July 2019)\r\nThe main OSF project with all documentation about the Reproducible Publications at AGILE Conferences and creation of the guidelines: https://osf.io/phmce/\r\nTODO: Evolution Repro Reviews in AGILE (2020-2023)…\r\nTODO: Quantitative vs qualitative research in GIScience\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:50+02:00"
    },
    {
      "path": "scene41.html",
      "title": "Act III &#183; Literate programming & notebooks",
      "description": "Scene 1 &#183; Literate programming & markdown\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP07] Understand the value of combining questions, source code and outcomes.\r\nContent…\r\nWe learn the structure and elements of a Markdown document\r\nWe introduce practical uses of Markdown for research\r\nWe introduce practical uses of Markdown for teaching\r\nOrganisation & materials\r\n[Estimated time: 2 hours]\r\nMarkdown is a very simple language for writing content especially for the web. This interactive tutorial markdowntutorial is a good starting point to learn the basics of Markdown.\r\nThis presentation “Markdown: uses for research and teaching” (slides)  summarises its advantages and provides some practical uses for research and teaching. It also includes a demo to generate different output formats (HTML, PDF, etc) from the same document in Markdown. The important thing is not the tool used, but that you think about the possibilities that Markdown can offer you to speed up the management of documents in different formats.\r\n\r\n\r\n\r\n\r\n\r\nAssignments\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:52+02:00"
    },
    {
      "path": "scene42.html",
      "title": "Act III &#183; Literate programming & notebooks",
      "description": "Scene 2 &#183; Quarto: an open-source scientific and technical publishing system\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP07] Understand the value of combining questions, source code and outcomes.\r\nContent…\r\nWe difference between knitr, R Markdown, and Quarto\r\nWe introduce practical uses of Quarto to generate static documents, websites, blogs, and presentations\r\nWe introduce how Quarto can be used for research and teaching\r\nOrganisation & materials\r\n[Estimated time: 2 hours]\r\nThis video explains in 1 minute what R Markdown is.\r\nQuarto is an open-source scientific and technical publishing system built on Pandoc and it’s the next-generation of RMarkdown. Check slidos by Mine Çetinkaya-Rundel & Julia Stewart Lowndes about “Hello Quarto: Share, Collaborate, Teach, Reimagine”, or watch the video at rstudio:conf(2022)\r\nWe rely on the excellent rstudio::conf 2022 Workshop - Getting Started with Quarto by Tom Mock, to learn the wide range of features that Quarto offers to produce elegantly formatted document and content.\r\nAssignments\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:54+02:00"
    },
    {
      "path": "scene43.html",
      "title": "Act III &#183; Literate programming & notebooks",
      "description": "Scene 3 &#183; Tools & resources\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nLearning outcomes…\r\nContent…\r\nOrganisation & materials\r\nAssignments\r\n\r\nLearning outcomes…\r\n[RRP07] Understand the value of combining questions, source code and outcomes.\r\nContent…\r\nWe learn existing resources and tools for streamlining reproducibility\r\nOrganisation & materials\r\n[Estimated time: 42 hours]\r\nBelow resources in no particular order. Subject to revision\r\nOSF project “Reproducible Publications at AGILE Conferences”\r\nTIER2 (enhancing Trust, Integrity and Efficiency in Research through next-level Reproducibility) project will increase reproducibility of scientific research results that will bring trust, integrity, and efficiency to the European Research Area (ERA) and the global Research and Innovation (R&I) system.\r\nCenter for Open Science, Open Science Framework (OSF) to, https://www.researchequals.com/\r\nGithub Template for RStudio on Binder / JupyterHub\r\nPosit’s Quarto playlist\r\nYouTube: R Consortium, Posit, R4DS Online Learning Community\r\nOpenScapes\r\nAssignments\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:56+02:00"
    },
    {
      "path": "schedule.html",
      "title": "Course schedule",
      "author": [],
      "contents": "\r\n\r\nContents\r\nAct I: Setting the stage\r\nAct II: Recommendations and practices\r\nAct III: Recommendations and practices: GIScience\r\nAct IV: Literate programming & notebooks (separate github repo - obgoing)\r\n\r\nThis is the current course schedule. Things might change, so check regularly for updates.\r\nAct I: Setting the stage\r\nWe cover learning outcomes RRP01 to RRP04. We look at landmark examples that have influenced the emphasis on reproducibility in the past decades and explain why reproducibility is so important in current scientific endeavour. We highlight which components may be reproducible and take a PhD perspective for reproducibility too. Next, we start with the Reproduction Plan by assessing the reproducibility criteria over research papers.\r\nScene 1: Reproducibility and replicability\r\nScene 2: PhD meets open science\r\nScene 3: Pre-reproducibility assessment\r\nAct II: Recommendations and practices\r\nWe cover learning outcomes RRP05 to RRP07. We comment and discuss recommendations and suggestions for getting started with reproducibility research practices and applying them to the Reproduction Plan to address the weakest aspects identified in Act I. Recommendations below are grouped according to when they are most likely to take them into consideration: before, during and after data analysis.\r\nScene 1: Before: basics to get started\r\nScene 2: During: data/coding practices and tools\r\nScene 3: After: writing and sharing reproducible resources\r\nAct III: Recommendations and practices: GIScience\r\nSame as Act II but focus on the GIScience discipline.\r\nScene 1: AGILE Guidelines for reproducible papers\r\nAct IV: Literate programming & notebooks (separate github repo - obgoing)\r\nWe cover learning outcomes RRP08 to RRP09.\r\nScene 1: Literate programming y markdown\r\nScene 2: Quarto: an open-source scientific and technical publishing system\r\nScene 3: Tools and resources\r\nRRP Learning Outcome 10 - Reproduction Plan - is a skill that will be developed throughout the course. Participants will submit their Reproduction Plan to make their next research project/work or technical writing more reproducible.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-03-28T10:55:58+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
