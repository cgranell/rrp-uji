[
  {
    "path": "posts/2021-07-16-piloto/",
    "title": "#2 - Grupo piloto en investigación reproducible",
    "description": "En este post recogemos unas notícias que cuestionan el poder del factor de impacto para la evaluación de la investigacion.",
    "author": [
      {
        "name": "Carlos Granell",
        "url": {}
      }
    ],
    "date": "2021-07-16",
    "categories": [
      "Pilot"
    ],
    "contents": "\r\nHola,\r\nSolo un par de notícias relacionadas con la investigación reproducible antes de que disfruteis de vuestras merecidas vacaciones.\r\nLa primera viene con el siguiente titular: La Universidad de Utrecht dejará de tener en cuenta el factor de impacto para medir la calidad de sus investigadores (Wilson 2021). Esta universidad holandesa dice que está dejando formalmente de tener en cuenta el factor de impacto, una medida “estándar” del éxito científico, y que interviene para bien o para mal en todas las decisiones de contratación y promoción. Para principios de 2022, todos sus departamentos juzgarán a sus académicos según otros estándares, incluido su compromiso con el trabajo en equipo y sus esfuerzos para promover la ciencia abierta, según el nuevo esquema de acreditación “Recognition and rewards” de la Universidad de Utrecht. A pesar de este gran salto, no se quedan ahí. Ese nuevo esquema de reconocimiento forma parte del programa Open Science de Utrecht, un esfuerzo brutal para hacer que la investigación sea más transparente y cooperativa. Ahí se dice que los encargados de los programas de ciencia abierta integrados en cada departamento evaluarán el progreso hacia la publicación de acceso abierto, la participación pública y el intercambio de datos. Ojalá este cambio de rumbo en las políticas de contratación y promoción se aplicará también en UJI.\r\nLa segunda es a nivel nacional a raíz de una carta abierta (Delgado-López-Cózar, Ràfols, and Abadal 2021) firmada por Emilio Delgado-López, Ismael Ràfols y Ernest Abadal, que reclaman un llamamiento a las autoridades españolas para cambiar el modelo de evaluación de la investigación en España, que tanta importancia concede a los indicadores bibliométricos (índice H, citaciones, etc), en general, y a los índices de impacto de revista, en particular. Pues bien, parece que esa carta ha generado algo de movimiento, y la semana que viene, 22 de julio, se celebra una mesa redonda donde se discutirán (entre los panelistas, representantes de ANECA, AEI, etc) sobre la necesidad de ese cambio de rumbo en la evaluación científica en España. Podéis registraros para la mesa redonda desde el link anterior, y/o seguir el debate por youtube en background mientras hacéis otras cosas.\r\nEste debate llega tardísimo, visto a la altura de película a la que está la Universidad de Utrecht que nos saca varios pueblos de ventaja. Pero bien, bienvenidas estas mesas redondas si los que toman las decisiones en políticas científicas se van con ideas de cambio real. ¿Y cómo os afecta a vosotros?. Hace pocos años, no se hablaba de esto. Ni por asomo. Se aceptaba el sacrosanto Factor de Impacto sin pestañear. A mi me da que este cambio se va a acelerar en pocos años. Esa es mi impresión. Espero que os anticipéis al futuro y toméis nota para que vuestra investigació sea dirigida por principios de ciencia abierta, datos FAIR, reproducibilidad, etc (recogidos en “Recognition and Rewards”) en vez de por el Factor de Impacto.\r\nSaludos y buen verano!\r\nCarlos\r\n\r\n\r\n\r\nDelgado-López-Cózar, E, I Ràfols, and E Abadal. 2021. “Letter: A Call for a Radical Change in Research Evaluation in Spain.” Profesional de La Información 30 (3): e300309. https://doi.org/10.3145/epi.2021.may.09.\r\n\r\n\r\nWilson, C. 2021. “Impact Factor Abandoned by Dutch University in Hiring and Promotion Decisions.” Nature 595 (465). https://dx.doi.org/10.1038/d41586-021-01759-5.\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-11-16T00:14:49+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-31-piloto/",
    "title": "#1 - Grupo piloto en investigación reproducible",
    "description": "En este post iniciamos una serie de mensajes para promover prácticas reproducibles dirigidas especialemnte a jóvenes investigadores Esta iniciativa _de prueba y experimental_ surgío tras terminar el curso de RRP en Mayo 2021 (RRP'21) y con el visto bueno de la Escuela de Doctorado.",
    "author": [
      {
        "name": "Carlos Granell",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [
      "Pilot"
    ],
    "contents": "\r\nHola,\r\nQue sepáis que no voy a daros trabajo por mostrar interés en este grupo piloto sobre investigación reproducible. Simplemente os informaré de cosas que atañen directamente a la reproducibilidad y las buenas prácticas en la investigación.\r\nNi que decir tiene que tenéis mi correo para contactarme directamente sobre cualquier cuestión relacionada con lo visto en el curso para el desarrollo de vuestra tesis doctorales.\r\nComentaros brevemente que el abril de 2021 pasado la Agencia Española de Investigación se adhirió a la Declaración DORA sobre evaluación de la investigación. Promete\r\n\r\n“revisar todas sus convocatorias y documentos de soporte a la evaluación para asegurar su correcta implementación”.\r\n\r\nAlgunas de las recomendaciones DORA que la AEI promete llevar a cabo (aunque no será un camino de rosas cambiar las políticas actuales basadas en el factor de impacto por su larga permanencia en la ciencia española) al adherirse son las siguientes (negritas son mías):\r\nNo utilice métricas basadas en revistas, como el factor de impacto, como una medida sustituta de la calidad de los artículos de investigación individuales, para evaluar las contribuciones de un científico individual, o en las decisiones de contratación, promoción o financiación.\r\nSea explícito sobre los criterios utilizados para evaluar la productividad científica de los solicitantes de fondos de investigación, especialmente para los investigadores que están iniciando su carrera investigadora, que el contenido científico de un artículo es mucho más importante que las métricas de publicación o la identidad de la revista en la que fue publicado.\r\nCon el fin de evaluar la investigación, considere el valor y el impacto de todos los resultados de la investigación (incluidos los conjuntos de datos y el software) además de las publicaciones de investigación, y considere una amplia gama de medidas de impacto que incluyan indicadores cualitativos, como la influencia sobre la política y prácticas científicas.\r\nComo veis, claramente se primará el contenido del artículo en detrimento del contenedor (revista y su índice de impacto). Por fin algo de sentido común en la ciencia española. Ojalá logremos (investigadores, universidades, ANECA, etc) dejar atrás la dependencia absoluta en el factor de impacto y primos cercanos para evaluar si el CV de un/a candidato/a es suficiente o no para una beca, contrato o promoción.\r\nLas pinceladas iniciales que vimos en el curso de RRP’21 cobran más sentido y se hacen más necesarias que nunca para vuestra futura carrera investigadora. Sed pacientes y agarraos a lo verdaderamente importante y no al factor de impacto. ¡Sois mucho más que un número!\r\nSaludos, Carlos\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-11-16T00:14:31+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-11-colophon-rrp21/",
    "title": "Colophon RRP21",
    "description": "Resumen final y mensaje de cierre de del curso RRP21.",
    "author": [
      {
        "name": "Carlos Granell",
        "url": {}
      }
    ],
    "date": "2021-05-11",
    "categories": [
      "RRP21"
    ],
    "contents": "\r\nLa idea de reproducción en ciencia no es algo nuevo. Las disputas entre Isaac Newton y John Falmsteed siglos atrás ya mostraban claramente los ingredientes de la reproducción y la replicación como mecanismos necesarios para el progreso de la ciencia. En palabras de Newton,\r\n\r\n“these and all your communications will be useless to me unless you can propose some practicable way or other of supplying me with observations … I want not your calculations, but your observations only.”\r\n\r\nEs innegable que la ciencia moderna se apoya en gran medida en la tecnología y la computación. Muchas disciplinas científicas se les puede calificar hasta cierto punto de “computacionales”. Algunas requieren de procesos computacionales a gran escala para llevar a cabo sus investigaciones, otras necesitan acceso a datos heterogéneos en formato digital, y otras necesitan procesos analíticos para obtener los resultados. De uno u otro modo, la diferencia con la época de Newton es que hablamos de una reproducibilidad computacional. En vez de pedirle “las observaciones en papel”, Newton en nuestros días le pediría a Falmsteed los “datos, scripts, y el entorno de computacional en el cual había realizado los cálculos”. Ha sido un cambio radical en el soporte, no cabe duda, pero la idea detrás de la reproducción sigue intacta: transparencia e integridad en el proceso científico.\r\nSin embargo, la forma de diseminar la investigación no ha cambiado radicalmente desde los tiempos de Newton. El contenido de un paper sigue siendo en esencia tal como era siglos atrás, mucho antes de la introducción de la computación y la tecnología en las metodologías de investigación. Para los científicos de siglos pasados la apariencia actual de un artículo científico sería muy familiar. Pero tendrían serios problemas en reproducir un artículo actual. En parte, claro, por el desconocimiento total de la tecnología moderna. Por otra parte, sin embargo, porque los datos y recursos para entender los resultados descritos en el artículo no se incluyen. “Algo falta aquí! El autor dice que procesa los datos pero ¿dónde están?”. Y añadirían desesperados, “escribirimos una carta al autor para pedirle los datos originales. Seguro que en un par de meses tendremos notícias suyas”.\r\n¿Qué diferencia un paper tradicional de uno reproducible? En su forma más simple, un párrafo más. Un párrafo que indique donde se pueden encontrar y como acceder a los datos, código, documentación, instrucciones, scripts, infraestructura computacional y, en definitiva, a cualquier recurso que se haya utilizado para llegar a los resultados y conclusiones expuestas en el artículo escrito. Un apartado de Data and Software Availabilty (DASA) en la sección de los métodos del artículo cumple con ese cometido. Fácil, ¿no?\r\nLo verdaderamente importante no es incluir la sección DASA en el artículo final. No me mal interpretés, ¡incluidla siempre que podáis! Lo verdaderamente importante es la sistematización de describir con sumo detalle todo el proceso científico llevado a cabo hasta su culminación en el artículo científico publicado. La sección DASA es solo la punta del iceberg, indica al lector “here’s my work”, donde encontrar y acceder a los recursos necesarios para la reproducción/replicación. Todo lo que no se ve, el resto del iceberg, que es inmenso comparado con la sección DASA, son las prácticas y hábitos para la investigación reproducible que habéis ido adquiriendo y aplicando en vuestra rutina diaria.\r\nNo se puede pensar en la reproducibilidad unos días antes de enviar un artículo para su revisión, como una tarea más equiparable a la recogida de biografías del resto de autores. Ser reproducible empieza mucho antes [@nature2021], cuando arranca el proyecto de investigación, durante la recogida de datos, durante el análisis, durante la redacción del artículo; en definitiva, durante toda la vida del proyecto. Ser reproducible implica un cambio en el proceso. La clave es el proceso, no el producto. Optimizando el proceso de forma reproducible, generareis productos (papers) reproducibles una y otra vez.\r\nEste curso no tenía por objetivo enseñaros a escribir secciones DASA para incluirlas en vuestros artículos. Eso es un efecto colateral. El objetivo primario del curso era promover un cambio de mentalidad en vuestro proceso de investigación y rutina de trabajo diaria, para que asimiléis como hábitos propios las prácticas y recomendaciones básicas vistas en este curso.\r\nEsperamos haberlo conseguido.\r\nCarlos y Sergi\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-11-15T22:20:35+01:00",
    "input_file": {}
  }
]
